{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipanjanS/training-fine-tuning-large-language-models-workshop-dhs2024/blob/main/Module-01-LLMs-Transformers-Generative-AI-Essentials/Module_01_LC2_Contextual_Embeddings_and_Semantic_Search_Engines_with_Transformers_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVemECCPfYg0"
      },
      "source": [
        "# Contextual Embeddings and Semantic Search Engines with Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contextual Embeddings in Transformers\n",
        "\n",
        "Contextual embeddings are different from plain word embeddings.\n",
        "\n",
        "Due to aspects like self-attention, each word's corresponding emebdding can be influenced by surrounding words context.\n",
        "\n",
        "e.g\n",
        "\n",
        "- They are going to **fire** him\n",
        "- He is sitting by the **fire**\n",
        "\n",
        "The word **fire** would have a different embedding vector because of other words when using transformer models\n",
        "\n",
        "Also you can typically average word embeddings in a document to get an overall document embedding"
      ],
      "metadata": {
        "id": "2YMlbN7m1ldK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by taking a few different documents."
      ],
      "metadata": {
        "id": "eisI4xVQ4DLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "-wkv5xS4-saa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = ['The cat is running on the stairs',\n",
        "        'A woman is eating a piece of bread.',\n",
        "        'A man is eating a pasta.']\n",
        "\n",
        "docs"
      ],
      "metadata": {
        "id": "Q319pYkE4HaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a pre-trained BERT Transformer model\n",
        "\n",
        "Here we will use a pre-trained transformer model to get contextual word embeddings and average them to get document embeddings.\n",
        "\n",
        "![](https://i.imgur.com/4uYtfkQ.png)\n",
        "\n",
        "Then we can compute simple cosine similarity between document embedding for each pair of the above documents"
      ],
      "metadata": {
        "id": "WeWt6yPK4jnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# model details: https://huggingface.co/google-bert/bert-base-uncased\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = AutoModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "QDNS_-Fg5OVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing Documents\n",
        "\n",
        "Transformers have been trained by first tokenizing the documents, hence each model comes with its own trained tokenizer which can break down a document into individual tokens (words) and each token would have a corresponding embedding.\n",
        "\n",
        "REMEMBER: We are not training any models here, just using an already pre-trained model on a lot of data and getting embeddings for our documents by passing them through the pre-trained model"
      ],
      "metadata": {
        "id": "waS_vWOI5T8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "JfVPUs7D5siB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = tokenizer(docs[0], return_tensors='pt')\n",
        "token_ids"
      ],
      "metadata": {
        "id": "u9kWtImR5ovI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key token ID elements above include\n",
        "\n",
        "#### Input IDs\n",
        "The input ids are often the only required parameters to be passed to the model as input. They are token indices, numerical representations of tokens building the sequences that will be used as input by the model. __You should mostly care about this in most cases__\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### Attention mask\n",
        "The attention mask is an optional argument used when batching sequences together. This argument indicates to the model which tokens should be attended to, and which should not (masked language modeling)\n",
        "\n",
        "<br/>\n",
        "\n",
        "#### Token Type IDs\n",
        "Some models’ purpose is to do sequence classification or question answering. These require two different sequences to be joined in a single “input_ids” entry, which usually is performed with the help of special tokens, such as the classifier ([CLS]) and separator ([SEP]) tokens. For example, the BERT model builds its two sequence input as such:\n",
        "\n",
        "```\n",
        ">>> # [CLS] SEQUENCE_A [SEP] SEQUENCE_B [SEP]\n",
        "```\n",
        "\n",
        "https://huggingface.co/transformers/glossary.html#token-type-ids"
      ],
      "metadata": {
        "id": "30uNtoBF6Nfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids"
      ],
      "metadata": {
        "id": "mG-H15k56ma4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[tokenizer.decode(id) for id in token_ids['input_ids'][0]]"
      ],
      "metadata": {
        "id": "Q7GmH7eu6uLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contextual_embeddings = model(**token_ids)[0]\n",
        "contextual_embeddings"
      ],
      "metadata": {
        "id": "Vxsm4bcB65Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contextual_embeddings.shape"
      ],
      "metadata": {
        "id": "QFbGCPLE8lmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "doc_embedding = torch.mean(contextual_embeddings, dim=1)[0]\n",
        "doc_embedding"
      ],
      "metadata": {
        "id": "VH00uOUA8ugo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_embedding.shape"
      ],
      "metadata": {
        "id": "q3egVLhU9CRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "m4EY7dlm9Dn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_token_ids = [tokenizer(doc, return_tensors='pt') for doc in docs]\n",
        "doc_token_ids"
      ],
      "metadata": {
        "id": "LgKbCJNv9GJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_contextual_embeddings = [model(**token_ids)[0] for token_ids in doc_token_ids]\n",
        "doc_contextual_embeddings"
      ],
      "metadata": {
        "id": "V_PiVoq59ai1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_embeddings = [torch.mean(contextual_embeddings, dim=1)[0] for contextual_embeddings in doc_contextual_embeddings]\n",
        "doc_embeddings"
      ],
      "metadata": {
        "id": "Tdxz-RSN9imF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_embeddings = [np.round(doc_embedding.detach().numpy(), 3) for doc_embedding in doc_embeddings]\n",
        "doc_embeddings"
      ],
      "metadata": {
        "id": "mAtLM8p79yHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_similarity(doc_embeddings)"
      ],
      "metadata": {
        "id": "bSRvYZJK9qVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "_37eYKoV93-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHruWvqUgO-x"
      },
      "source": [
        "# Finding semantic similarity with Pre-trained Embeddings\n",
        "\n",
        "Here we will leverage already pre-trained embedding models \\ deep learning models to extract embeddings from sentences and find out their semantic similarity.\n",
        "\n",
        "Models we will look at:\n",
        "\n",
        "- Transformers\n",
        "\n",
        "# Semantic Search\n",
        "\n",
        "Semantic search seeks to improve search accuracy by understanding the content of the search query. In contrast to traditional search engines which only find documents based on lexical matches, semantic search can also find synonyms.\n",
        "\n",
        "\n",
        "The idea behind semantic search is to embed all entries in your corpus, whether they be sentences, paragraphs, or documents, into a vector space.\n",
        "\n",
        "At search time, the query is embedded into the same vector space and the closest embeddings from your corpus are found. These entries should have a high semantic overlap with the query.\n",
        "\n",
        "![](https://i.imgur.com/FyUCkG5.png)\n",
        "\n",
        "___[Created By: Dipanjan (DJ)](https://www.linkedin.com/in/dipanjans/)___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x26l6_VpnSIn"
      },
      "source": [
        "# Fun with Embeddings: Simple Search Engine!\n",
        "\n",
        "Let's create a corpus of documents which will be our source on which we will run text searches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfvzmamjTN71"
      },
      "source": [
        "documents = [\n",
        "  \"Quantum mechanics describes the behavior of very small particles.\",\n",
        "  \"Photosynthesis is the process by which green plants make food using sunlight.\",\n",
        "  \"Shakespeare's plays are a testament to English literature.\",\n",
        "  \"Artificial Intelligence aims to create machines that can think and learn.\",\n",
        "  \"The pyramids of Egypt are historical monuments that have stood for thousands of years.\",\n",
        "  \"Biology is the study of living organisms and their interactions with the environment.\",\n",
        "  \"Music therapy can aid in the mental well-being of individuals.\",\n",
        "  \"The Milky Way is just one of billions of galaxies in the universe.\",\n",
        "  \"Economic theories help understand the distribution of resources in society.\",\n",
        "  \"Yoga is an ancient practice that involves physical postures and meditation.\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Robust Semantic Search Engines with Transformers"
      ],
      "metadata": {
        "id": "_B5DpkigjGQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "JzHIna2aw4UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dependencies"
      ],
      "metadata": {
        "id": "cb0Te1G3pXYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch"
      ],
      "metadata": {
        "id": "FADwzx6phWPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Pre-trained Transformer Model"
      ],
      "metadata": {
        "id": "V5jH3qIJpsS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/microsoft/MiniLM-L12-H384-uncased\n",
        "# MiniLM: Small and Fast Pre-trained Models for Language Understanding and Generation\n",
        "# MiniLMv1-L12-H384-uncased: 12-layer, 384-hidden, 12-heads, 33M parameters, 2.7x faster than BERT-Base\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L12-v2')"
      ],
      "metadata": {
        "id": "hInenjHshkAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "bIYouxlZ1ZEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a corpus of documents"
      ],
      "metadata": {
        "id": "3lftCkcFp3cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = ['Quantum mechanics describes the behavior of very small particles.',\n",
        " 'Photosynthesis is the process by which green plants make food using sunlight.',\n",
        " \"Shakespeare's plays are a testament to English literature.\",\n",
        " 'Artificial Intelligence aims to create machines that can think and learn.',\n",
        " 'The pyramids of Egypt are historical monuments that have stood for thousands of years.',\n",
        " 'Biology is the study of living organisms and their interactions with the environment.',\n",
        " 'Music therapy can aid in the mental well-being of individuals.',\n",
        " 'The Milky Way is just one of billions of galaxies in the universe.',\n",
        " 'Economic theories help understand the distribution of resources in society.',\n",
        " 'Yoga is an ancient practice that involves physical postures and meditation.']"
      ],
      "metadata": {
        "id": "LYybmS0Sejd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "id": "pz9HLzPz-YQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get document embeddings"
      ],
      "metadata": {
        "id": "D-llyc6yp-WK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings = model.encode(documents)"
      ],
      "metadata": {
        "id": "9uNIJzSwhSOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings.shape"
      ],
      "metadata": {
        "id": "JrdGZue1pbNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings, document_embeddings.shape"
      ],
      "metadata": {
        "id": "r5NdvBJfesRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "id": "2sGtYRK41tzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings[0].shape"
      ],
      "metadata": {
        "id": "ak4AK_vp12Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings[0]"
      ],
      "metadata": {
        "id": "OIuA5kGg1xtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's try to find the most similar document for one query"
      ],
      "metadata": {
        "id": "hm9TZcPyqQFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New Query"
      ],
      "metadata": {
        "id": "ME8l8GelrM5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text = 'What is AI?'\n",
        "new_text"
      ],
      "metadata": {
        "id": "d1tSZLrnqL-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Embedding for New Query"
      ],
      "metadata": {
        "id": "f_BSrJ6GrO0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_text_embedding = model.encode(new_text)\n",
        "new_text_embedding.shape"
      ],
      "metadata": {
        "id": "2Y3ID2biqWBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Cosine Similarity Score of Document Emebddings compared to New Query Embedding"
      ],
      "metadata": {
        "id": "3PEIK3WPrSAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cos_scores = util.pytorch_cos_sim(new_text_embedding, document_embeddings)[0]\n",
        "cos_scores"
      ],
      "metadata": {
        "id": "81KJgv7CqdRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Most Similar Document ID"
      ],
      "metadata": {
        "id": "LNRuuOomrZZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_results = torch.topk(cos_scores, k=1)\n",
        "top_results"
      ],
      "metadata": {
        "id": "RhxgDJY3qnzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = top_results.indices[0]\n",
        "idx"
      ],
      "metadata": {
        "id": "YJJChy-6qrOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Most Similar Document"
      ],
      "metadata": {
        "id": "OwN-b2VJreWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents[idx]"
      ],
      "metadata": {
        "id": "xM49_k6YrJAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a function to return the top similar document based on any query\n",
        "\n",
        "__Replace `<REPLACE WITH CODE HERE>` sections with your own code__"
      ],
      "metadata": {
        "id": "Q-YNRhmbrnDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_search_engine(query, embedder_model):\n",
        " <REPLACE WITH CODE HERE>"
      ],
      "metadata": {
        "id": "d1AEDYNdhfW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try out the function"
      ],
      "metadata": {
        "id": "dvnpjNtervq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = 'Tell me about AI'\n",
        "semantic_search_engine(new_sentence, model)"
      ],
      "metadata": {
        "id": "u6waCgoHiSrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = 'Do you know about the pyramids?'\n",
        "semantic_search_engine(new_sentence, model)"
      ],
      "metadata": {
        "id": "5fNNYN-lifn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = 'How do plants survive?'\n",
        "semantic_search_engine(new_sentence, model)"
      ],
      "metadata": {
        "id": "lod8wnLziqG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = 'How do animals survive?'\n",
        "semantic_search_engine(new_sentence, model)"
      ],
      "metadata": {
        "id": "Fe7fNo20rCws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2njm6pFrD10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}